{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "dataset = pd.read_csv(\"data/dataset_train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_dataset(dataframe):\n",
    "    dataframe = dataframe.drop(\"capital-gain\", axis=1)\n",
    "    dataframe = dataframe.drop(\"capital-loss\", axis=1)\n",
    "#     dataframe = dataframe.drop(\"native-country\", axis=1)\n",
    "    dataframe[\"workclass\"] = dataframe[\"workclass\"].map({'Private': 0.5, 'Self-emp-not-inc': 0.5,'Local-gov': 0.5, '?':0.5,'State-gov': 0.7, 'Self-emp-inc': 1, 'Federal-gov': 0.85, 'Without-pay': 0.2,'Never-worked':0.1})\n",
    "    dataframe[\"education\"] = dataframe[\"education\"].map({'HS-grad': 0.4, 'Some-college': 0.4,'Bachelors': 0.75,'Masters': 0.75, 'Assoc-voc': 0.5, '11th': 0.3, 'Assoc-acdm': 0.5,'10th':0.3, '7th-8th': 0.3,'Prof-school':0.95, '9th': 0.3, '12th': 0.3,'Doctorate': 0.95,'5th-6th': 0.3, '1st-4th': 0.1,'Preschool': 0.1})\n",
    "    dataframe[\"marital-status\"] = dataframe[\"marital-status\"].map({'Married-civ-spouse': 0.7, 'Never-married': 0.2, 'Divorced': 0.2,'Widowed': 0.2, 'Separated': 0.2, 'Married-spouse-absent': 0.5,'Married-AF-spouse': 0.5})\n",
    "    dataframe[\"occupation\"] = dataframe[\"occupation\"].map({'Prof-specialty': 0.8, 'Craft-repair': 0.5, 'Exec-managerial': 0.8,'Adm-clerical': 0.4, 'Sales': 0.5, 'Other-service': 0.3,'Machine-op-inspct': 0.3, '?': 0.5,'Transport-moving': 0.5, 'Handlers-cleaners': 0.3,'Farming-fishing': 0.4,'Tech-support': 0.45,'Protective-serv': 0.45,'Priv-house-serv': 0.1, 'Armed-Forces': 0.4})\n",
    "    dataframe[\"relationship\"] = dataframe[\"relationship\"].map({'Husband': 0.9, 'Not-in-family': 0.3,'Own-child': 0.1, 'Wife':0.9,'Other-relative': 0.3, 'Unmarried': 0.3})\n",
    "    dataframe[\"race\"] = dataframe[\"race\"].map({'White': 0.5, 'Black': 0.3,'Asian-Pac-Islander': 0.5, 'Amer-Indian-Eskimo':0.3,'Other': 0.3})\n",
    "    dataframe[\"gender\"] = dataframe[\"gender\"].map({'Male': 0.7, 'Female': 0.3})\n",
    "    dataframe[\"native-country\"] = dataframe[\"native-country\"].map({'Mexico':0.3 ,'Puerto-Rico':0.3 ,'El-Salvador':0.3 ,'Dominican-Republic':0.3 ,'Columbia':0.3, 'United-States' :0.5 , '?' :0.5 , 'Cuba':0.5, 'Philippines' :0.5 , 'Germany' :0.5 , 'China' :0.5 , 'India' :0.5 , 'England' :0.5 , 'Jamaica' :0.5 , 'South' :0.5 , 'Guatemala' :0.5 , 'Vietnam' :0.5 , 'Poland' :0.5 , 'Italy' :0.5 , 'Haiti' :0.5 , 'Portugal' :0.5 , 'Japan' :0.5 , 'Peru' :0.5 , 'Taiwan' :0.5 , 'Nicaragua' :0.5 , 'Ecuador' :0.5 , 'Iran' :0.5 , 'Greece' :0.5 , 'Thailand' :0.5 , 'Trinadad&Tobago' :0.5 , 'Outlying-US(Guam-USVI-etc)' :0.5 , 'Cambodia' :0.5 , 'Ireland' :0.5 , 'Laos' :0.5 , 'France' :0.5 , 'Hong' :0.5 , 'Honduras' :0.5 , 'Scotland' :0.5 , 'Yugoslavia' :0.5 , 'Hungary' :0.5 , 'Holand-Netherlands':0.5, 'Canada':0.7})\n",
    "    dataframe[\"income\"] = dataframe[\"income\"].map({'<=50K':0, '>50K':1})\n",
    "    dataframe[\"age\"] = (dataframe[\"age\"]-17)/73\n",
    "    dataframe[\"educational-num\"] = (dataframe[\"educational-num\"]-1)/15\n",
    "    dataframe[\"hours-per-week\"]  = dataframe[\"hours-per-week\"].apply(lambda x: 1 if x > 80 else (x-1)/80)\n",
    "    dataframe[\"fnlwgt\"] = dataframe[\"fnlwgt\"].apply(lambda x: 1 if x > 700000 else (x-12285)/787715)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm = encode_dataset(dataset)\n",
    "X_dataset = data_norm.drop('income', axis=1)\n",
    "y_dataset = data_norm['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata = pd.read_csv(\"data/p_test.csv\")\n",
    "pdata_norm = encode_dataset(pdata)\n",
    "X_p = pdata_norm.drop('income', axis=1)\n",
    "y_p = pdata_norm['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=300, max_features=5)\n",
    "clf.fit(X_dataset, y_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_p)\n",
    "print(\"RF accuracy: \", accuracy_score(y_p, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=300, max_features=10)\n",
    "clf.fit(X_dataset, y_dataset)\n",
    "y_pred = clf.predict(X_p)\n",
    "print(\"RF accuracy: \", accuracy_score(y_p, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 150, stop = 700, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_dataset, y_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=516,min_samples_split=5,min_samples_leaf=4,max_features=\"sqrt\",max_depth=80,bootstrap=True)\n",
    "clf.fit(X_dataset, y_dataset)\n",
    "y_pred = clf.predict(X_p)\n",
    "print(\"RF accuracy: \", accuracy_score(y_p, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.read_csv(\"data/trainset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_dataset_2(dataframe):\n",
    "    dataframe[\"workclass\"] = dataframe[\"workclass\"].map({'Private': 0, 'Self-emp-not-inc': 1,'Local-gov': 2, '?':0,'State-gov': 4, 'Self-emp-inc': 5, 'Federal-gov': 6, 'Without-pay': 7,'Never-worked':8 })\n",
    "    dataframe[\"education\"] = dataframe[\"education\"].map({'HS-grad': 0, 'Some-college': 1,'Bachelors': 2, '?':0,'Masters': 4, 'Assoc-voc': 5, '11th': 6, 'Assoc-acdm': 7,'10th':8, '7th-8th': 9,'Prof-school':10, '9th': 10, '12th': 11,'Doctorate': 12,'5th-6th': 13, '1st-4th': 14,'Preschool': 15   })\n",
    "    dataframe[\"marital-status\"] = dataframe[\"marital-status\"].map({'Married-civ-spouse': 0, 'Never-married': 1, 'Divorced': 2,'Widowed': 3, 'Separated': 4, 'Married-spouse-absent': 5,'Married-AF-spouse': 6 })\n",
    "    dataframe[\"occupation\"] = dataframe[\"occupation\"].map({'Prof-specialty': 0, 'Craft-repair': 1, 'Exec-managerial': 2,'Adm-clerical': 3, 'Sales': 4, 'Other-service': 5,'Machine-op-inspct': 6, '?': 0,'Transport-moving': 8, 'Handlers-cleaners': 9,'Farming-fishing': 10,'Tech-support': 11,'Protective-serv': 12,'Priv-house-serv': 13, 'Armed-Forces': 14})\n",
    "    dataframe[\"relationship\"] = dataframe[\"relationship\"].map({'Husband': 0, 'Not-in-family': 1,'Own-child': 2, 'Wife':3,'Other-relative': 4, 'Unmarried': 5})\n",
    "    dataframe[\"race\"] = dataframe[\"race\"].map({'White': 0, 'Black': 1,'Asian-Pac-Islander': 2, 'Amer-Indian-Eskimo':3,'Other': 4})\n",
    "    dataframe[\"gender\"] = dataframe[\"gender\"].map({'Male': 1, 'Female': 0})\n",
    "#     dataframe[\"native-country\"] = dataframe[\"native-country\"].replace(['United-States', '?'], 0)\n",
    "#     dataframe[\"native-country\"] = dataframe[\"native-country\"].replace(['Mexico', 'Philippines', 'Puerto-Rico', 'Canada', 'Germany', 'El-Salvador', 'Cuba', 'India', 'England', 'China', 'Dominican-Republic', 'Italy', 'South', 'Columbia', 'Japan', 'Jamaica', 'Poland', 'Guatemala', 'Haiti', 'Vietnam', 'Taiwan', 'Iran', 'Portugal', 'Ecuador', 'Nicaragua', 'Greece', 'Peru', 'Ireland', 'France', 'Cambodia', 'Thailand', 'Hong', 'Trinadad&Tobago', 'Honduras', 'Laos', 'Outlying-US(Guam-USVI-etc)', 'Yugoslavia', 'Hungary', 'Scotland', 'Holand-Netherlands'], 1)\n",
    "    dataframe[\"native-country\"] = dataframe[\"native-country\"].map({'Mexico':3 ,'Puerto-Rico':3 ,'El-Salvador':3 ,'Dominican-Republic':3 ,'Columbia':3, 'United-States' :0 , '?' :0 , 'Cuba':1, 'Philippines' :1 , 'Germany' :1 , 'China' :1 , 'India' :1 , 'England' :1 , 'Jamaica' :1 , 'South' :1 , 'Guatemala' :1 , 'Vietnam' :1 , 'Poland' :1 , 'Italy' :1 , 'Haiti' :1 , 'Portugal' :1 , 'Japan' :1 , 'Peru' :1 , 'Taiwan' :1 , 'Nicaragua' :1 , 'Ecuador' :1 , 'Iran' :1 , 'Greece' :1 , 'Thailand' :1, 'Trinadad&Tobago' :1 , 'Outlying-US(Guam-USVI-etc)' :1 , 'Cambodia' :1 , 'Ireland': 1 , 'Laos' :1 , 'France' :2 , 'Hong' :2 , 'Honduras' :2 , 'Scotland' :2 , 'Yugoslavia' :2 , 'Hungary' :2 , 'Holand-Netherlands':2, 'Canada':3})\n",
    "    dataframe[\"income\"] = dataframe[\"income\"].map({'<=50K':0, '>50K':1})\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_norm = encode_dataset_2(trainset)\n",
    "X_train = trainset_norm.drop('income', axis=1)\n",
    "y_train = trainset_norm['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                False\n",
       "workclass          False\n",
       "fnlwgt             False\n",
       "education          False\n",
       "educational-num    False\n",
       "marital-status     False\n",
       "occupation         False\n",
       "relationship       False\n",
       "race               False\n",
       "gender             False\n",
       "capital-gain       False\n",
       "capital-loss       False\n",
       "hours-per-week     False\n",
       "native-country     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = pd.read_csv(\"data/testset.csv\")\n",
    "testset_norm = encode_dataset_2(testset)\n",
    "X_test = testset_norm.drop('income', axis=1)\n",
    "y_test = testset_norm['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 600, num = 300)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(1, 210, num = 200)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16, 17, 18, 19, 20]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16, 17, 18, 19, 20]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>34816</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>221172</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>286869</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1668</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>348592</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>94235</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1977</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
       "0   21          0   34816          5               11               0   \n",
       "1   42          1  221172          0                9               2   \n",
       "2   68          0  286869          9                4               3   \n",
       "3   30          0  348592          0                9               0   \n",
       "4   30          0   94235          2               13               0   \n",
       "\n",
       "   occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
       "0           3             3     0       0             0             0   \n",
       "1           1             1     0       1             0             0   \n",
       "2           0             1     0       0             0          1668   \n",
       "3           6             0     0       1             0             0   \n",
       "4           0             0     0       1             0          1977   \n",
       "\n",
       "   hours-per-week  native-country  \n",
       "0              12               0  \n",
       "1              40               0  \n",
       "2              40               0  \n",
       "3              44               0  \n",
       "4              50               0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 200, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=271,min_samples_split=2,min_samples_leaf=4,max_features=\"auto\",max_depth=40,bootstrap=True)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(\"RF2 accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data = pd.read_csv(\"data/p_test.csv\")\n",
    "p_norm = encode_dataset_2(p_data)\n",
    "X_p = p_data.drop('income', axis=1)\n",
    "y_p = p_data['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF3 accuracy:  0.8671307196232982\n"
     ]
    }
   ],
   "source": [
    "y_ppred = clf.predict(X_p)\n",
    "print(\"RF3 accuracy: \", accuracy_score(y_p, y_ppred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2 = pd.read_csv(\"data/dataset_train.csv\")\n",
    "dts_norm = encode_dataset_2(dataset_2)\n",
    "X_dts = dts_norm.drop('income', axis=1)\n",
    "y_dts = dts_norm['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=271,min_samples_split=2,min_samples_leaf=4,max_features=\"auto\",max_depth=40,bootstrap=True)\n",
    "clf.fit(X_dts, y_dts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ppred = clf.predict(X_p)\n",
    "print(\"RF3 accuracy: \", accuracy_score(y_p, y_ppred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 600, num = 300)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [4,5,6,7,8,9,10,11,12,13,14]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(1, 210, num = 200)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16, 17, 18, 19, 20]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16, 17, 18, 19, 20]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KHO MAU LUON NE\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_dts, y_dts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=314,min_samples_split=17,min_samples_leaf=2,max_features=\"sqrt\",max_depth=16,bootstrap=True)\n",
    "clf.fit(X_dts, y_dts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ppred = clf.predict(X_p)\n",
    "print(\"RF4 accuracy: \", accuracy_score(y_p, y_ppred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(list_data, filename):\n",
    "    list_data = [\"<=50K\" if item ==0 else \">50K\" for item in list_data]\n",
    "    with open(filename, mode='wt', encoding='utf-8') as myfile:\n",
    "        myfile.write('\\n'.join(str(line) for line in list_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(y_ppred, \"linhph_03.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
