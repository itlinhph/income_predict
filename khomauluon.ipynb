{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "dataset = pd.read_csv(\"data/dataset_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_dataset_2(dataframe):\n",
    "    dataframe[\"workclass\"] = dataframe[\"workclass\"].map({'Private': 0, 'Self-emp-not-inc': 1,'Local-gov': 2, '?':0,'State-gov': 4, 'Self-emp-inc': 5, 'Federal-gov': 6, 'Without-pay': 7,'Never-worked':8 })\n",
    "    dataframe[\"education\"] = dataframe[\"education\"].map({'HS-grad': 0, 'Some-college': 1,'Bachelors': 2, '?':0,'Masters': 4, 'Assoc-voc': 5, '11th': 6, 'Assoc-acdm': 7,'10th':8, '7th-8th': 9,'Prof-school':10, '9th': 10, '12th': 11,'Doctorate': 12,'5th-6th': 13, '1st-4th': 14,'Preschool': 15   })\n",
    "    dataframe[\"marital-status\"] = dataframe[\"marital-status\"].map({'Married-civ-spouse': 0, 'Never-married': 1, 'Divorced': 2,'Widowed': 3, 'Separated': 4, 'Married-spouse-absent': 5,'Married-AF-spouse': 6 })\n",
    "    dataframe[\"occupation\"] = dataframe[\"occupation\"].map({'Prof-specialty': 0, 'Craft-repair': 1, 'Exec-managerial': 2,'Adm-clerical': 3, 'Sales': 4, 'Other-service': 5,'Machine-op-inspct': 6, '?': 0,'Transport-moving': 8, 'Handlers-cleaners': 9,'Farming-fishing': 10,'Tech-support': 11,'Protective-serv': 12,'Priv-house-serv': 13, 'Armed-Forces': 14})\n",
    "    dataframe[\"relationship\"] = dataframe[\"relationship\"].map({'Husband': 0, 'Not-in-family': 1,'Own-child': 2, 'Wife':3,'Other-relative': 4, 'Unmarried': 5})\n",
    "    dataframe[\"race\"] = dataframe[\"race\"].map({'White': 0, 'Black': 1,'Asian-Pac-Islander': 2, 'Amer-Indian-Eskimo':3,'Other': 4})\n",
    "    dataframe[\"gender\"] = dataframe[\"gender\"].map({'Male': 1, 'Female': 0})\n",
    "#     dataframe[\"native-country\"] = dataframe[\"native-country\"].replace(['United-States', '?'], 0)\n",
    "#     dataframe[\"native-country\"] = dataframe[\"native-country\"].replace(['Mexico', 'Philippines', 'Puerto-Rico', 'Canada', 'Germany', 'El-Salvador', 'Cuba', 'India', 'England', 'China', 'Dominican-Republic', 'Italy', 'South', 'Columbia', 'Japan', 'Jamaica', 'Poland', 'Guatemala', 'Haiti', 'Vietnam', 'Taiwan', 'Iran', 'Portugal', 'Ecuador', 'Nicaragua', 'Greece', 'Peru', 'Ireland', 'France', 'Cambodia', 'Thailand', 'Hong', 'Trinadad&Tobago', 'Honduras', 'Laos', 'Outlying-US(Guam-USVI-etc)', 'Yugoslavia', 'Hungary', 'Scotland', 'Holand-Netherlands'], 1)\n",
    "    dataframe[\"native-country\"] = dataframe[\"native-country\"].map({'Mexico':3 ,'Puerto-Rico':3 ,'El-Salvador':3 ,'Dominican-Republic':3 ,'Columbia':3, 'United-States' :0 , '?' :0 , 'Cuba':1, 'Philippines' :1 , 'Germany' :1 , 'China' :1 , 'India' :1 , 'England' :1 , 'Jamaica' :1 , 'South' :1 , 'Guatemala' :1 , 'Vietnam' :1 , 'Poland' :1 , 'Italy' :1 , 'Haiti' :1 , 'Portugal' :1 , 'Japan' :1 , 'Peru' :1 , 'Taiwan' :1 , 'Nicaragua' :1 , 'Ecuador' :1 , 'Iran' :1 , 'Greece' :1 , 'Thailand' :1, 'Trinadad&Tobago' :1 , 'Outlying-US(Guam-USVI-etc)' :1 , 'Cambodia' :1 , 'Ireland': 1 , 'Laos' :1 , 'France' :2 , 'Hong' :2 , 'Honduras' :2 , 'Scotland' :2 , 'Yugoslavia' :2 , 'Hungary' :2 , 'Holand-Netherlands':2, 'Canada':3})\n",
    "    dataframe[\"income\"] = dataframe[\"income\"].map({'<=50K':0, '>50K':1})\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2 = pd.read_csv(\"data/dataset_train.csv\")\n",
    "dts_norm = encode_dataset_2(dataset_2)\n",
    "X_dts = dts_norm.drop('income', axis=1)\n",
    "y_dts = dts_norm['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=40, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=4, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=271, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=271,min_samples_split=2,min_samples_leaf=4,max_features=\"auto\",max_depth=40,bootstrap=True)\n",
    "clf.fit(X_dts, y_dts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data = pd.read_csv(\"data/p_test.csv\")\n",
    "p_norm = encode_dataset_2(p_data)\n",
    "X_p = p_data.drop('income', axis=1)\n",
    "y_p = p_data['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF3 accuracy:  0.8670283550005118\n"
     ]
    }
   ],
   "source": [
    "y_ppred = clf.predict(X_p)\n",
    "print(\"RF3 accuracy: \", accuracy_score(y_p, y_ppred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 600, num = 300)]\n",
    "max_features = [4,5,6,7,8,9,10,11,12,13,14]\n",
    "max_depth = [int(x) for x in np.linspace(1, 210, num = 200)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2,4,6,8,10,12,14,16,18,20,22,24]\n",
    "min_samples_leaf = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 150 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 353 tasks      | elapsed: 18.6min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 32.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=200, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [100, 101, 103, 105, 106, 108, 110, 111, 113, 115, 116, 118, 120, 121, 123, 125, 126, 128, 130, 131, 133, 135, 136, 138, 140, 141, 143, 145, 146, 148, 150, 151, 153, 155, 156, 158, 160, 161, 163, 165, 166, 168, 170, 171, 173, 175, 176, 178, 180, 181, 183, 185, 18...': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KHO MAU LUON NE\n",
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 200, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "rf_random.fit(X_dts, y_dts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 576,\n",
       " 'min_samples_split': 4,\n",
       " 'min_samples_leaf': 7,\n",
       " 'max_features': 4,\n",
       " 'max_depth': 121,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=121, max_features=4, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=7, min_samples_split=4,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=576, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=576,min_samples_split=4,min_samples_leaf=7,max_features=4,max_depth=121,bootstrap=True)\n",
    "clf.fit(X_dts, y_dts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF4 accuracy:  0.8671307196232982\n"
     ]
    }
   ],
   "source": [
    "y_ppred = clf.predict(X_p)\n",
    "print(\"RF4 accuracy: \", accuracy_score(y_p, y_ppred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
